<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Larry shi kun 的小黑屋</title>
  
  <subtitle>石坤</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://shi163.github.io/"/>
  <updated>2018-11-28T12:43:17.000Z</updated>
  <id>https://shi163.github.io/</id>
  
  <author>
    <name>Larry shikun</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>多项式回归</title>
    <link href="https://shi163.github.io/Machine-Learning/First/"/>
    <id>https://shi163.github.io/Machine-Learning/First/</id>
    <published>2018-11-28T12:43:14.000Z</published>
    <updated>2018-11-28T12:43:17.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="多项式回归"><a href="#多项式回归" class="headerlink" title=" 多项式回归 "></a><font color="#A52A2A" size="5" face="微软雅黑"> 多项式回归 </font></h1><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a><font color="#A52A2A" size="3" face="微软雅黑">代码</font></h2><font color="#A52A2A" size="2" face="微软雅黑">R中做多项式回归（不考虑交互以及正交变换的情况）</font><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">x&lt;-as.numeric(df[,<span class="number">1</span>]) <span class="comment">#x非空</span></span><br><span class="line">y&lt;-as.numeric(df[,<span class="number">2</span>]) <span class="comment">#y非空，长度与x一致</span></span><br><span class="line"></span><br><span class="line">degree = <span class="number">4</span> <span class="comment">#多项式系数</span></span><br><span class="line">level = <span class="number">0.93</span> <span class="comment">#置信水平</span></span><br><span class="line">getCI = <span class="literal">TRUE</span> <span class="comment">#是否显示confidence均值上下界，不是prediction个体值上下界</span></span><br><span class="line">getFitted = <span class="literal">TRUE</span> <span class="comment">#是否显示拟合值</span></span><br><span class="line">getResidual= <span class="literal">TRUE</span> <span class="comment">#是否显示残差</span></span><br><span class="line"></span><br><span class="line">len &lt;- length(x)</span><br><span class="line">result &lt;- list()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span>(len == <span class="number">1</span>) &#123;</span><br><span class="line">  CI &lt;- matrix(as.numeric(c(y[<span class="number">1</span>], y[<span class="number">1</span>], y[<span class="number">1</span>])), nrow = <span class="number">1</span>, ncol = <span class="number">3</span>)</span><br><span class="line">&#125;<span class="keyword">else</span> &#123;</span><br><span class="line">  <span class="keyword">if</span>(degree &gt;= <span class="number">2</span>) &#123;</span><br><span class="line">    xnam &lt;- paste(<span class="string">"I(x"</span>, <span class="number">2</span>:degree, sep = <span class="string">"^"</span>)</span><br><span class="line">    fo &lt;- paste(<span class="string">"y ~ x +"</span>, paste0(xnam, <span class="string">")"</span>, collapse=<span class="string">"+"</span>))</span><br><span class="line">  &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">    fo &lt;- y ~ x</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  model &lt;- lm(fo, na.action = na.omit)</span><br><span class="line">  lev &lt;- <span class="number">0.95</span></span><br><span class="line">  </span><br><span class="line">  <span class="keyword">if</span>(getCI) &#123;</span><br><span class="line">    lev &lt;- level</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  CI &lt;- unname(predict(model, data.frame(x), level=lev, interval=<span class="string">"confidence"</span>))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span>(getFitted) &#123;</span><br><span class="line">  result$fitted &lt;- CI[,<span class="number">1</span>]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span>(getCI) &#123;</span><br><span class="line">  result$lower &lt;- CI[,<span class="number">2</span>]</span><br><span class="line">  result$upper &lt;- CI[,<span class="number">3</span>]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span>(getResidual) &#123;</span><br><span class="line">  result$resid &lt;- y - CI[,<span class="number">1</span>]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">result</span><br></pre></td></tr></table></figure><p><img src="http://pis9aieqm.bkt.clouddn.com/R%20log.png" alt="R"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;多项式回归&quot;&gt;&lt;a href=&quot;#多项式回归&quot; class=&quot;headerlink&quot; title=&quot; 多项式回归 &quot;&gt;&lt;/a&gt;&lt;font color=&quot;#A52A2A&quot; size=&quot;5&quot; face=&quot;微软雅黑&quot;&gt; 多项式回归 &lt;/font&gt;&lt;/h1&gt;&lt;h2 id=
      
    
    </summary>
    
      <category term="Machine Learning" scheme="https://shi163.github.io/categories/Machine-Learning/"/>
    
    
      <category term="R" scheme="https://shi163.github.io/tags/R/"/>
    
  </entry>
  
  <entry>
    <title>线性回归</title>
    <link href="https://shi163.github.io/Machine-Learning/liner-regression/"/>
    <id>https://shi163.github.io/Machine-Learning/liner-regression/</id>
    <published>2018-11-28T12:37:51.000Z</published>
    <updated>2018-11-28T12:37:55.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="线性回归"><a href="#线性回归" class="headerlink" title=" 线性回归 "></a><font color="#A52A2A" size="5" face="微软雅黑"> 线性回归 </font></h1><p>因变量Y是连续变量，否则考虑广义线性模型;每行数据之间相互独立，否则考虑时间序列，重复测量，纵向数据;残差分布独立于自变量X用于模型诊断和改进;因变量Y和自变量X之间是线性关系可用样条函数描述。</p><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a><font color="#A52A2A" size="3" face="微软雅黑">代码</font></h2><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 1. linear regression</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.1 one independent variable</span></span><br><span class="line"></span><br><span class="line">model1 &lt;- lm(TestC ~ Age)</span><br><span class="line"></span><br><span class="line"><span class="comment"># if data.wide not attached</span></span><br><span class="line"><span class="comment"># model1 &lt;- lm(TestC ~ Age, data=data.wide)</span></span><br><span class="line"></span><br><span class="line">model1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.2 multiple independent variables</span></span><br><span class="line"></span><br><span class="line">model2 &lt;- lm(TestC ~ Age + TestA + TestB)</span><br><span class="line">model2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.3 categorical independent variable (into dummy variable)</span></span><br><span class="line"></span><br><span class="line">model3 &lt;- lm(TestC ~ Age + relevel(Sex,<span class="string">"Male"</span>))  <span class="comment"># male as reference group</span></span><br><span class="line">model3</span><br><span class="line"></span><br><span class="line">model3.1 &lt;- lm(TestC ~ Age + relevel(Sex,<span class="string">"Female"</span>)) <span class="comment"># female as reference group</span></span><br><span class="line">model3.1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.4 interaction term</span></span><br><span class="line"></span><br><span class="line">model4 &lt;- lm(TestC ~ Age*relevel(Sex,<span class="string">"Male"</span>))  <span class="comment"># "*" both interaction and main effect</span></span><br><span class="line">model4</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model4.1 &lt;- lm(TestC ~ Age + Age:relevel(Sex,<span class="string">"Male"</span>)) <span class="comment"># ":" only interaction y ~ x*z == y ~ x + z + x:z</span></span><br><span class="line">model4.1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.Model summary</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.1 model fit</span></span><br><span class="line">summary(model4) <span class="comment"># F test p value, R^2, adj R^2</span></span><br><span class="line">AIC(model4) <span class="comment"># the lower the better</span></span><br><span class="line">BIC(model4) <span class="comment"># the lower the better</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.2 coefficients</span></span><br><span class="line"></span><br><span class="line">summary(model4)$coefficients   <span class="comment"># coefficients, standard error, p-value</span></span><br><span class="line">confint(model4, level=<span class="number">0.95</span>)    <span class="comment"># 95% confidence interval</span></span><br><span class="line"></span><br><span class="line">coef(model4)      <span class="comment"># extract coefficients</span></span><br><span class="line">coef(model4)[<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. Prediction</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># predict within data</span></span><br><span class="line">predict(model4)</span><br><span class="line"></span><br><span class="line"><span class="comment"># generate new patient data</span></span><br><span class="line">new.patient &lt;- data.frame(Age=c(<span class="number">30</span>, <span class="number">35</span>, <span class="number">40</span>),Sex=c(<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>))</span><br><span class="line">new.patient$Sex &lt;- factor(new.patient$Sex, </span><br><span class="line">                        levels=c(<span class="number">0</span>,<span class="number">1</span>),</span><br><span class="line">                        labels=c(<span class="string">"Male"</span>, <span class="string">"Female"</span>))</span><br><span class="line"></span><br><span class="line">new.patient</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict in new patient data</span></span><br><span class="line">new.patient$TestC_hat &lt;- predict(model4,newdata = new.patient)</span><br><span class="line"></span><br><span class="line">new.patient</span><br></pre></td></tr></table></figure><p><img src="http://pis9aieqm.bkt.clouddn.com/R%20log.png" alt="R"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;线性回归&quot;&gt;&lt;a href=&quot;#线性回归&quot; class=&quot;headerlink&quot; title=&quot; 线性回归 &quot;&gt;&lt;/a&gt;&lt;font color=&quot;#A52A2A&quot; size=&quot;5&quot; face=&quot;微软雅黑&quot;&gt; 线性回归 &lt;/font&gt;&lt;/h1&gt;&lt;p&gt;因变量Y是连续变
      
    
    </summary>
    
      <category term="Machine Learning" scheme="https://shi163.github.io/categories/Machine-Learning/"/>
    
    
      <category term="R" scheme="https://shi163.github.io/tags/R/"/>
    
  </entry>
  
</feed>
