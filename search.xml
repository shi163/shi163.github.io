<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[HoltWinners时序分析]]></title>
    <url>%2FMachine-Learning%2Ftimeseries%2F</url>
    <content type="text"><![CDATA[HoltWinners时序分析 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687# 时间列# tcol: time column, ascendingly sorted, equispaced## 数据列# dcol: a numeric vector, time series value at each time stamp## 趋势(beta)# beta: boolean flag, add trend effect or not## 季节因子(gamma)# gamma: boolean flag, add seasonal effect or not## 季节效应：加法效应,乘法效应# seasonal: string, choose what type of seasonal effect, "additive" or "multiplicative"## 预测周期(几年)# pperiod: period to do prediction## 置信区间# getPI: boolean flag, add prediction interval or not## level: 置信水平## 时间单位:(时间单位)# timeUnit: time unit# # alphaValue: alpha value# alphaValue = 0.3D;## betaValue: beta value# betaValue = 0.1D;## gammaValue: gamma value# gammaValue = 0.1D;#construct R time series objectlen &lt;- length(tcol)if(len &lt; 2) &#123; nas &lt;- c(NA) length(nas) &lt;- len result &lt;- list(his = nas, fitted = nas, lower = nas, upper=nas)&#125;else &#123; start &lt;- tcol[1] gap &lt;- tcol[2] - tcol[1] frequency &lt;- timeUnit / gap # 此处需要前期处理 timeType·gap 和timeUnit ; tsObject &lt;- ts(dcol, start=start, frequency=frequency) params &lt;- c(alpha = alphaValue, beta = betaValue, gamma = gammaValue) #build HoltWinters time series model if(beta &amp;&amp; gamma)&#123; hwModel &lt;- HoltWinters(tsObject, seasonal=seasonal, optim.start=params) &#125;else if(!beta &amp;&amp; gamma)&#123; hwModel &lt;- HoltWinters(tsObject, beta=FALSE, seasonal=seasonal, optim.start=params) &#125;else if(beta &amp;&amp; !gamma)&#123; hwModel &lt;- HoltWinters(tsObject, gamma=FALSE, optim.start=params) &#125;else&#123; hwModel &lt;- HoltWinters(tsObject, beta=FALSE, gamma=FALSE, optim.start=params) &#125; lev = 0.95 if(getPI) &#123; lev = level &#125; #use model to do prediction pred &lt;- predict(hwModel, pperiod, prediction.interval=getPI, level=lev) hisFit &lt;- hwModel$fitted[,1] fitLen &lt;- length(hisFit) nas &lt;- c(NA) length(nas) &lt;- len - fitLen hisFit &lt;- c(nas, hisFit) #put all required vectors in a list if(getPI)&#123; result &lt;- list(hisFit=hisFit,fitted=pred[,1],lower=pred[,3],upper=pred[,2]) &#125;else&#123; result &lt;- list(hisFit=hisFit,fitted=pred[,1]) &#125;&#125;result]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>R</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[K均值聚类]]></title>
    <url>%2FMachine-Learning%2FK-means-cluster%2F</url>
    <content type="text"><![CDATA[K均值聚类 代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889num &lt;- 2 #number of columns of data matrixselectK = TRUE #if true, select optimal k,轮廓系数法maxK = 6 #maximum number of clusters (used when selectK is set to be true)selectK = FALSEk = 5 # number of clustersgetPC = TRUE #if true, get principle componentx&lt;-as.numeric(df[,1]) #x非空y&lt;-as.numeric(df[,2]) #y非空dataMatrix &lt;- cbind(x,y)rsize &lt;- nrow(dataMatrix)if(is.null(rsize)) &#123; rsize &lt;- 0&#125;if((selectK &amp;&amp; rsize &lt; 3) || (!selectK &amp;&amp; rsize &lt; k + 1)) &#123; nas &lt;- c(NA) length(nas) &lt;- rsize result &lt;- list(cluster = as.character(nas), pc1 = nas, pc2 = nas)&#125;else &#123; #if "selectK" flag is set to be true, select optimal k by according to average #silhouette of each k, the one that maximizes average silhouette is the optimal one if(selectK)&#123; computeSilhouette &lt;- function(data,cntrs) &#123; dd &lt;- NULL k &lt;- nrow(cntrs) for(i in 1:k) &#123; xr &lt;- sweep(data,2,cntrs[i,],"-") dd&lt;-cbind(dd,apply(xr^2,1,sum)) &#125; dd &lt;- apply(dd,1,sort)[1:2,] (dd[2,]-dd[1,])/dd[2,] &#125; if(maxK &gt; rsize - 1) &#123; maxK &lt;- rsize - 1 &#125; choices &lt;- 2:maxK avgSilhouette &lt;- rep(0,length(choices)) for(k in choices) &#123; kmModel &lt;- kmeans(dataMatrix,centers=k,nstart=10) avgSilhouette[k-1] &lt;- mean(computeSilhouette(dataMatrix,kmModel$centers)) &#125; optimalClusterNumber &lt;- choices[which.max(avgSilhouette)] &#125; #build final model based on the value of k if(selectK)&#123; finalKmModel &lt;- kmeans(dataMatrix,centers=optimalClusterNumber, nstart=10) &#125;else&#123; finalKmModel &lt;- kmeans(dataMatrix,centers=k, nstart=10) &#125; #for plotting purpose, project original data on 2-D space using principle component pcCount &lt;- ncol(prcomp(dataMatrix)$rotation) if(pcCount &gt; 2) &#123; pcCount &lt;- 2 &#125; if(getPC)&#123; pc &lt;- dataMatrix%*%(prcomp(dataMatrix)$rotation[,1:pcCount]) if(pcCount == 2) &#123; result &lt;- list(cluster=as.character(finalKmModel$cluster),pc1=pc[,1],pc2=pc[,2]) &#125;else &#123; pc2 &lt;- c(NA) length(pc2) &lt;- length(pc[,1]) pc2 &lt;- as.numeric(pc2) result &lt;- list(cluster=as.character(finalKmModel$cluster),pc1=pc[,1],pc2=pc2) &#125; &#125;else&#123; result &lt;- list(cluster=as.character(finalKmModel$cluster)) &#125;&#125;result]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>R</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多项式回归]]></title>
    <url>%2FMachine-Learning%2FFirst%2F</url>
    <content type="text"><![CDATA[多项式回归 代码R中做多项式回归（不考虑交互以及正交变换的情况） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647x&lt;-as.numeric(df[,1]) #x非空y&lt;-as.numeric(df[,2]) #y非空，长度与x一致degree = 4 #多项式系数level = 0.93 #置信水平getCI = TRUE #是否显示confidence均值上下界，不是prediction个体值上下界getFitted = TRUE #是否显示拟合值getResidual= TRUE #是否显示残差len &lt;- length(x)result &lt;- list()if(len == 1) &#123; CI &lt;- matrix(as.numeric(c(y[1], y[1], y[1])), nrow = 1, ncol = 3)&#125;else &#123; if(degree &gt;= 2) &#123; xnam &lt;- paste("I(x", 2:degree, sep = "^") fo &lt;- paste("y ~ x +", paste0(xnam, ")", collapse="+")) &#125;else &#123; fo &lt;- y ~ x &#125; model &lt;- lm(fo, na.action = na.omit) lev &lt;- 0.95 if(getCI) &#123; lev &lt;- level &#125; CI &lt;- unname(predict(model, data.frame(x), level=lev, interval="confidence"))&#125;if(getFitted) &#123; result$fitted &lt;- CI[,1]&#125;if(getCI) &#123; result$lower &lt;- CI[,2] result$upper &lt;- CI[,3]&#125;if(getResidual) &#123; result$resid &lt;- y - CI[,1]&#125;result]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>R</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线性回归]]></title>
    <url>%2FMachine-Learning%2Fliner-regression%2F</url>
    <content type="text"><![CDATA[线性回归 因变量Y是连续变量，否则考虑广义线性模型;每行数据之间相互独立，否则考虑时间序列，重复测量，纵向数据;残差分布独立于自变量X用于模型诊断和改进;因变量Y和自变量X之间是线性关系可用样条函数描述。 代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667## 1. linear regression# 1.1 one independent variablemodel1 &lt;- lm(TestC ~ Age)# if data.wide not attached# model1 &lt;- lm(TestC ~ Age, data=data.wide)model1# 1.2 multiple independent variablesmodel2 &lt;- lm(TestC ~ Age + TestA + TestB)model2# 1.3 categorical independent variable (into dummy variable)model3 &lt;- lm(TestC ~ Age + relevel(Sex,"Male")) # male as reference groupmodel3model3.1 &lt;- lm(TestC ~ Age + relevel(Sex,"Female")) # female as reference groupmodel3.1# 1.4 interaction termmodel4 &lt;- lm(TestC ~ Age*relevel(Sex,"Male")) # "*" both interaction and main effectmodel4model4.1 &lt;- lm(TestC ~ Age + Age:relevel(Sex,"Male")) # ":" only interaction y ~ x*z == y ~ x + z + x:zmodel4.1# 2.Model summary# 2.1 model fitsummary(model4) # F test p value, R^2, adj R^2AIC(model4) # the lower the betterBIC(model4) # the lower the better# 2.2 coefficientssummary(model4)$coefficients # coefficients, standard error, p-valueconfint(model4, level=0.95) # 95% confidence intervalcoef(model4) # extract coefficientscoef(model4)[2]# 3. Prediction# predict within datapredict(model4)# generate new patient datanew.patient &lt;- data.frame(Age=c(30, 35, 40),Sex=c(0,1,1))new.patient$Sex &lt;- factor(new.patient$Sex, levels=c(0,1), labels=c("Male", "Female"))new.patient# predict in new patient datanew.patient$TestC_hat &lt;- predict(model4,newdata = new.patient)new.patient]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>R</tag>
      </tags>
  </entry>
</search>
